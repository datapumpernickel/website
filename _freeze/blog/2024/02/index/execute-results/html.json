{
  "hash": "8c8e07fee241faa5112fae2f798c634d",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Part I: Visualizing changes across versions of conflict data from UCDP\"\ndate: 2024-11-08\ndescription: \"Using the conflictoR package we query conflict data from the Uppsala Conflict Data Center and visualize changes across different versions of the data\"\nimage: \"index_files/figure-html/fig-1-replication-1.png\"\ncategories:\n  - r\n  - conflict data \nformat:\n  html: \n    shift-heading-level-by: 1\ninclude-before-body:\n  text: |\n    <style>\n      .no-stripe .gt_table tr.odd {\n        --bs-table-striped-bg: transparent;\n      }\n      \n      .gt_footnote {\n        text-align: left !important;\n      }\n    </style>\ncitation: true\nbibliography: references.bib\nnocite: |\n  @davies2024organized, @gleditsch2002armed, @eck2007violence, @sundberg2012introducing\n---\n\n\n\n\n\n## The replication problem\n\nWhen doing data analysis one of the problems we face is to make sure that our analysis is replicable. In a quantitative study, in which many of the outcomes are produced by code from pre-coded data, in theory, this should be easily achieved. However, the ongoing replication crisis in different scientific fields has shown to be rather durable. In the following I will address two broad topics in this field, the one of retrospective changes in the data and better maintainable code. In Part I, only a broad overview of these changes will be provided, in Part II I want to explore those changes a bit more across regions. \n\n### 1 Retrospective changes\n\nWhile working with data, I have more often than not come across the issue that I download some dataset and work on the analysis. A few month go by where I work on other things and when getting back to the project I download the data again, except now the results have changed! Not only was the data possibly extended to the present day, which would be expectable, but there might also be retrospective changes to existing datasets. This is very common in datasets in political science, where good data is hard to come by and new information might change how we code past events. \n\nOne case that I came across recently is conflict data, so information on how many conflicts take place in a given time frame and area and also how many fatalities are associated with these. \n\nThe [Uppsala Conflict Data Program (UCDP)](https://www.uu.se/en/department/peace-and-conflict-research/research/ucdp/), as they write themselves, *is the worldâ€™s main provider of data on organized violence and the oldest ongoing data collection project for civil war, with a history of almost 40 years. Its definition of armed conflict has become the global standard of how conflicts are systematically defined and studied*. \n\nUCDP offers us a nice insight into this problem, because they properly version their datasets, allowing us to retroactively access outdated datasets and even provide detailed codebooks for each different version and what has changed. See for example [here](https://ucdp.uu.se/downloads/ucdpprio/versionhistory-acd-241.pdf).\n\n![Versioning Example from UCDP](versioning_example.png)\n\n\n### 2 Code that is understandable, reproducable and hence helps to replicate\n\nWhen writing code that makes data available that I use frequently, I try to make my code reproducible. This is firstly to save myself work in the future, but it will also make it easier for others to use my code to replicate my results. One great way of doing this is to package code into an actual R-package. If you are interested in doing this, the single-most helpful and wonderful resource is this book [here](https://r-pkgs.org) by Hadley Wickham and Jennifer Bryan. \n\n#### The conflictoR package\n\nSpecifically with the resource above, I have found that the two packages which promised to allow access to the API in R where not fully functional for my use-case (either because they did not allow filtering and contributions in a [private gitlab](https://gitlab.com/dante-sttr/conflictr) were complicated or because the package actually was [not fully developed](https://github.com/chris-dworschak/ucdp.api) and seemed stale). Hence I quickly wrote my own code, which I then packaged, so I can use it again in the future and others can use it to access the same data. \n\nYou can find the package at: [https://github.com/datapumpernickel/conflictoR](https://github.com/datapumpernickel/conflictoR) and install it as follows: \n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrequire(devtools)\ndevtools::install_github(\"datapumpernickel/conflictoR\")\n```\n:::\n\n\n\n## Visualizing the UCDP conflict counts\n\n### Getting and cleaning the data\nNow for starters, let's replicate the graph that appears on the dashboard of UCDP for the number of conflicts in the world. For that we need three datasets, `c(\"ucdpprioconflict\", \"nonstate\", \"onesided\")`. \n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the query\"}\n## loading libraries\nlibrary(tidyverse)\nlibrary(conflictoR)\nlibrary(purrr)\n\n\n## making a dataframe with all combinations of datasets and versions\ndatasets  = c(\"ucdpprioconflict\", \"nonstate\", \"onesided\")\nversion <- \"24.1\"\n\n## querying this data using the conflictoR package\nstate <- cl_get_data(resource = datasets[1], \n                     version =  version) |>\n  ## selecting the columns we need\n  transmute(\n    dataset = datasets[1],\n    year = as.character(year),\n    conflict_id,\n    version = \"24.1\"\n  ) \n\nnonstate <- cl_get_data(resource = datasets[2], version =  version) |>\n  transmute(\n    dataset = datasets[2],\n    year = as.character(year),\n    conflict_id,\n    version = \"24.1\"\n  ) \n\nonesided <- cl_get_data(resource = datasets[3], version =  version) |>\n  transmute(\n    dataset = datasets[3],\n    year = as.character(year),\n    conflict_id,\n    version = \"24.1\"\n  ) \n\n## clean the data to count actual conflicts and merge the sets\nclean_full_data <- bind_rows(state,\n                             nonstate,\n                             onesided)|>\n  count(year, version, dataset) |> \n  group_by(year, dataset) |> \n  mutate(year = as.numeric(year))\n```\n:::\n\n\n\nWith the three datasets queried and cleaned, as well as having counted the unique conflict_ids per year, dataset and version, we can now move on to visualize the numbers. \n\n::: {.panel-tabset}\n\n## Plot\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Replication for UCDP official conflict count dashboard.](index_files/figure-html/fig-1-replication-1.png){#fig-1-replication fig-align='center' width=90%}\n:::\n:::\n\n\n## Code\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n\n\ncolors <- c(\n  \"ucdpprioconflict\" = \"#D55E00\",    # red for State-Based Violence\n  \"nonstate\" = \"#009E73\",            # green for Non-State Violence\n  \"onesided\" = \"#F0E442\"             # yellow for One-Sided Violence\n)\n\nlabels <- c(\n  \"ucdpprioconflict\" = \"State-Based Violence\",\n  \"nonstate\" = \"Non-State Violence\",\n  \"onesided\" = \"One-Sided Violence\"\n)\nclean_full_data <- read_rds(\"data1.rds\")\n\n# Generate the plot\nggplot(data = clean_full_data |> \n         filter(year >= 1975 & year <= 2023, version == \"24.1\")) +\n  geom_line(aes(x = year, y = n, color = dataset, group = dataset), size = 1) +\n  geom_point(aes(x = year, y = n, color = dataset), size = 2) +\n  scale_color_manual(values = colors, \n                     labels = labels) +\n  labs(title = \"Number of Conflicts\", subtitle = \"1975-2023\", caption = \"using version 24.1 of all datasets\") +\n  scale_x_continuous(breaks = seq(1975, 2023, 5)) +\n  scale_y_continuous(breaks = seq(0, 100, 20), limits = c(0,100)) +\n  theme_minimal(base_size = 14) +\n  theme(\n    plot.background = element_rect(fill = \"black\", color = NA),\n    panel.background = element_rect(fill = \"black\", color = NA),\n    panel.grid.major = element_line(color = \"grey20\"),\n    panel.grid.minor = element_line(color = \"grey30\"),\n    axis.text = element_text(color = \"white\"),\n    plot.caption = element_text(color = \"white\"),\n    axis.title = element_blank(),\n    plot.title = element_text(color = \"white\", size = 16, face = \"bold\"),\n    plot.subtitle = element_text(color = \"white\", size = 12),\n    legend.position = \"bottom\",\n    legend.title = element_blank(),\n    legend.text = element_text(color = \"white\", size = 10),\n    legend.background = element_rect(fill = \"black\", color = NA)\n  )\n```\n:::\n\n\n:::\n\n\n## Tracking changes across different versions\n\nNow in order to look at how these numbers change across different versions, lets get the datasets for all versions: \n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n## making a dataframe with all combinations of datasets and versions\nall_combinations  <- tidyr::expand_grid(\n  datasets  = c(\"ucdpprioconflict\", \"nonstate\", \"onesided\"),\n  versions  = c(\"24.1\", \"23.1\", \"22.1\", \"21.1\", \"20.1\", \"17.2\", \"18.1\", \"19.1\")\n)\n\n## querying this data using the conflictoR package\nfull_data <- map2(\n  all_combinations$datasets,\n  all_combinations$versions,\n  ~ cl_get_data(.x, .y) |>\n    transmute(\n      dataset = .x,\n      year = as.character(year),\n      conflict_id,\n      version = .y\n    )\n)\n\n```\n:::\n\n\n\nNow that we queried all the dataset-version combinations, we can bind the datasets together and actually count the conflicts in each year for each version and dataset. \n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n## clean the data to count actual conflicts\nclean_full_data <- full_data |>\n  reduce(bind_rows) |>\n  count(year, version, dataset) |> \n  group_by(year, dataset) |> \n  mutate(n_max = max(n),\n         n_min = min(n)) |> \n  mutate(year = as.numeric(year))\n```\n:::\n\n\n\nIt becomes quite evident that not too seldomly the number of conflicts is changed from one version to another, even if the actual conflict is quite some years back! This should probably not come as a surprise, since areas of violent conflict are usually hard to gain access to and collecting information in this environment is dangerous and news articles about these incidents are probably often not accurate, until some time has passed to allow for thorough investigation. It speaks to the dedication of researchers at UCDP that they incorporate changes so far back into their datasets. \n\n::: {.panel-tabset}\n\n## Plot\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-1.png){fig-align='center' width=90%}\n:::\n:::\n\n\n\n\n## Code\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n\n## making a dataframe with all combinations of datasets and versions\nall_combinations  <- tidyr::expand_grid(\n  datasets  = c(\"ucdpprioconflict\", \"nonstate\", \"onesided\"),\n  versions  = c(\"24.1\", \"23.1\", \"22.1\", \"21.1\", \"20.1\", \"17.2\", \"18.1\", \"19.1\")\n)\n\n## querying this data using the conflictoR package\nfull_data <- map2(\n  all_combinations$datasets,\n  all_combinations$versions,\n  ~ cl_get_data(.x, .y) |>\n    mutate(\n      dataset = .x,\n      year = as.character(year),\n      conflict_id,\n      version = .y\n    )\n)\n\n## clean the data to count actual conflicts\nclean_full_data <- full_data |>\n  map( ~ .x |> distinct(conflict_id, year, version, dataset)) |>\n  reduce(bind_rows) |>\n  count(year, version, dataset) |> \n  group_by(year, dataset) |> \n  mutate(n_max = max(n),\n         n_min = min(n)) |> \n  mutate(year = as.numeric(year))\n\nggplot(data = clean_full_data |> \n         filter(year %in% 2000:2024)) +\n  geom_ribbon(aes(x = year, ymax = n_max, ymin = n_min), \n                fill = \"grey80\")+\n  geom_point(aes(x = year, y = n,group =version, color = version),\n             alpha = 0.7)+\n  labs(title = \"Changes in conflict counts\", subtitle =\"over different versions of yearly totals\")+\n  facet_wrap(.~dataset, ncol = 1)+\n  theme_minimal()+\n  scale_x_continuous(breaks = seq(2000, 2024, 2))+\n    scale_color_brewer(palette = \"Dark2\")\n```\n:::\n\n\n:::\n\nThe fact that we can see the largest amount of changes in the last 10 years, might be due to the fact, that the API only allows us to query the last 7 versions dating back to 2017. \n\nIntuitively, one would assume that lack of information leads to a systematic underestimation of conflict data. \nHence, one question I wanted to answer was: **Are conflicts usually underestimated and then corrected upwards or are conflict periods also overestimated?**\n\nTo answer this question, for each dataset I compared the changes between current and previous version and checked if the previous year-dataset-version tryad was smaller than the current one or if there was no change at all. \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code to clean and prepare the data\"}\nchanges_analysis <- clean_full_data |> \n  group_by(dataset, year) |> \n  arrange(dataset, year, version) |> \n  mutate(lag_n = lag(n),\n         biased_downward = n>lag_n,\n         perc_change = ((n/lag_n)-1)*100,\n         change = n!= lag_n) |> \n  filter(change) |> \n  ungroup()\n```\n:::\n\n\n\nI found 167 periods were data was corrected ex post. A majority, in total 153 of these were corrected upwards. In addition, we can see that more than half of these episodes experience a change of roundabout 2.5 - 5% change upwards, whereas there is some really stark outliers, where the number of conflicts changes by a staggering 20%. \n\n::: {.panel-tabset}\n\n## Plot\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-10-1.png){fig-align='center' width=90%}\n:::\n:::\n\n\n\n## Code\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(patchwork)\np1 <- ggplot(changes_analysis)+\n  geom_boxplot(aes(biased_downward, perc_change)) +\n    geom_hline(aes(yintercept = 0), color= \"#bd5b54\", alpha = 0.8)+\n  theme_minimal()+\n  labs(\n       x = \"\", \n       y = \"Change in % of original value\",\n       caption = \"Uppsala Conflict Data Program, ucdp.uu.se, version 17.2 through 24.1 of resources: 'onesided', 'ucdpprioconflict' and 'nonstate'\")+\n  theme(plot.caption = element_text(face = \"italic\",size = 7 ))\n\np2 <- ggplot(changes_analysis |> count(biased_downward))+\n  geom_col(aes(x = 1, y = n, group = biased_downward, fill = biased_downward), position = \"stack\")+\n  coord_flip()+\n  theme_minimal()+\n  theme(legend.position = \"top\",\n        axis.text.y = element_blank(),\n        axis.title.y = element_blank(),\n        panel.grid.minor.y = element_blank(),\n        legend.title = element_text(size = 9),\n        legend.text = element_text(size = 8))+\n  scale_fill_manual(values = c(\"#e7a169\",\"#846e9a\"))+\n  labs(title = \"Corrections in percent of original value\", \n       subtitle = \"by directional change\", fill = \"Counts were corrected upwards\")\n\np2 / p1 + plot_layout(heights = c(1,5))\n```\n:::\n\n\n\n:::\n\n\n## Conclusion\n\nWe saw that it is quite easy to provide some interesting insights into how conflict episodes changed retrospectively, but this was only so straight forward, because UCDP on the one hand provides an API for easy access to their data and secondly, very meticulously versions different versions of their dataset. The takeaway from this hence should be: \n\na) be careful when interpreting this data, you might be underestimating conflict episodes by a few percent across the board \n\nand \n\nb) always make sure you make transparent which version of a dataset you are using, so others can replicate your analysis (and of course attribute the source). \n\nThis seems straight forward, but large data providers, such as one of the single most important sources for Trade Data, [UN Comtrade](https://comtradeplus.un.org), do not version their datasets in this way and you might never be able to replicate your analysis, if you did not make a snapshot of the data by yourself and share it with others. \n\n\n\n\n---\nnocite: |\n  @davies2024organized, @gleditsch2002armed, @eck2007violence, @sundberg2012introducing\n---\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}